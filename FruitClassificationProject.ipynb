{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9706097c",
   "metadata": {},
   "source": [
    "## Package Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba68b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   # Directory Package\n",
    "import warnings\n",
    "\n",
    "#Importing Scientific computing package for python. Library that provides a multidimential array\n",
    "# object, various derived objects (such as masked arrays and matrices), and an assortment of \n",
    "# routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting,\n",
    "# selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random\n",
    "# simulation and much more\n",
    "import numpy as np\n",
    "\n",
    "from numpy import genfromtxt\n",
    "\n",
    "#Importing Pythons Open Source Data Analysis and manipulation library\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import style\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import kaggle\n",
    "\n",
    "import random as rd\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, Conv3D, MaxPooling2D, MaxPooling3D, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#Importing Pythons Open Computer Vision Library that is designed to solve computer vision problems.\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pathlib  #Object-Oriented Filesystem paths functionality\n",
    "                #This module offers classes representing filesystem paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915581d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kaggle.api.dataset_list()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44dc4440",
   "metadata": {},
   "source": [
    "## Download Dataset ##\n",
    "\n",
    "Download the Kaggle [Fruits 360](https://www.kaggle.com/datasets/moltean/fruits) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb3793d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle datasets download moltean/fruits\n",
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(\"fruits.zip\", mode=\"r\") as zip_file:\n",
    "    #zip_file.printdir()\n",
    "    for file in zip_file.namelist():\n",
    "        if file.startswith('fruits-360_dataset/fruits-360'):\n",
    "            zip_file.extract(file, path='.')\n",
    "\n",
    "zip_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92271ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 100\n",
    "X = []    # Data\n",
    "Z = []    # Classification\n",
    "\n",
    "def assign_label(img, fruit_type):\n",
    "    return fruit_type\n",
    "\n",
    "def make_train_data(fruit_type, dir): \n",
    "    for img in tqdm(os.listdir(dir)):       #tqdm shows a status bar in the jupyter environment\n",
    "        label = assign_label(img, fruit_type)\n",
    "        path = os.path.join(dir, img)\n",
    "        try:\n",
    "            img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "            #img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            X.append(np.array(img))\n",
    "            Z.append(str(label))\n",
    "        except cv2.error:\n",
    "            print(\"image read and resize failed\")\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcef828a",
   "metadata": {},
   "source": [
    "## Set up Directory Structure ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = pathlib.Path(r\"fruits-360\\data-set\")\n",
    "\n",
    "#Iterating down the subtree of root directory and Creating a list of all fruit class Directories \n",
    "sub_directory_paths = list(root_directory.glob('*'))   \n",
    "\n",
    "#for file_path in directory_paths:\n",
    "#  print(file_path)\n",
    "\n",
    "#Checking The number of directories in the list\n",
    "#print(len(directory_paths))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "234e2f32",
   "metadata": {},
   "source": [
    "## Create Training Data ##\n",
    "Iterate over subdirectory paths and pull each subpath out to get the basename which is used to create the class name in the first parameter (os.path.basename(subpaths)) and use that subpaths path to include the location of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c825bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subpaths in sub_directory_paths:\n",
    "    make_train_data(os.path.basename(subpaths), subpaths)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08b5b73e",
   "metadata": {},
   "source": [
    "## Output data for Eye Test ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8da700",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 2)\n",
    "fig.set_size_inches(15, 15)\n",
    "for i in range(5):\n",
    "    for j in range(2):\n",
    "        l = rd.randint(0, len(Z))\n",
    "        ax[i,j].imshow(cv2.cvtColor(X[l], cv2.COLOR_BGR2RGB))\n",
    "        ax[i,j].set_title('Fruit: ' + Z[l])\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d064b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Z)\n",
    "Y = to_categorical(Y, 131)\n",
    "X = np.array(X)\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc935426",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf77957",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "rd.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d1a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size= (5,5), padding = 'Same', activation='relu', input_shape = (100, 100, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size= (3,3), padding='Same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=96, kernel_size=(3,3), padding= 'Same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(131, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5755485",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "red_lr = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f32b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef01a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd83fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "History = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                              epochs=epochs, validation_data=(x_test, y_test), \n",
    "                              verbose=1, steps_per_epoch=x_train.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9816ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(History.history['loss'])\n",
    "plt.plot(History.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
